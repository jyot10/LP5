{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c063421d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dab04801",
   "metadata": {},
   "outputs": [],
   "source": [
    "BostonTrain = pd.read_csv(\"boston_test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "154a6646",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>crim</th>\n",
       "      <th>zn</th>\n",
       "      <th>indus</th>\n",
       "      <th>chas</th>\n",
       "      <th>nox</th>\n",
       "      <th>rm</th>\n",
       "      <th>age</th>\n",
       "      <th>dis</th>\n",
       "      <th>rad</th>\n",
       "      <th>tax</th>\n",
       "      <th>ptratio</th>\n",
       "      <th>black</th>\n",
       "      <th>lstat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>0.02729</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>7.185</td>\n",
       "      <td>61.1</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2</td>\n",
       "      <td>242</td>\n",
       "      <td>17.8</td>\n",
       "      <td>392.83</td>\n",
       "      <td>4.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6</td>\n",
       "      <td>0.02985</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>6.430</td>\n",
       "      <td>58.7</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3</td>\n",
       "      <td>222</td>\n",
       "      <td>18.7</td>\n",
       "      <td>394.12</td>\n",
       "      <td>5.21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>0.14455</td>\n",
       "      <td>12.5</td>\n",
       "      <td>7.87</td>\n",
       "      <td>0</td>\n",
       "      <td>0.524</td>\n",
       "      <td>6.172</td>\n",
       "      <td>96.1</td>\n",
       "      <td>5.9505</td>\n",
       "      <td>5</td>\n",
       "      <td>311</td>\n",
       "      <td>15.2</td>\n",
       "      <td>396.90</td>\n",
       "      <td>19.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "      <td>0.21124</td>\n",
       "      <td>12.5</td>\n",
       "      <td>7.87</td>\n",
       "      <td>0</td>\n",
       "      <td>0.524</td>\n",
       "      <td>5.631</td>\n",
       "      <td>100.0</td>\n",
       "      <td>6.0821</td>\n",
       "      <td>5</td>\n",
       "      <td>311</td>\n",
       "      <td>15.2</td>\n",
       "      <td>386.63</td>\n",
       "      <td>29.93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10</td>\n",
       "      <td>0.17004</td>\n",
       "      <td>12.5</td>\n",
       "      <td>7.87</td>\n",
       "      <td>0</td>\n",
       "      <td>0.524</td>\n",
       "      <td>6.004</td>\n",
       "      <td>85.9</td>\n",
       "      <td>6.5921</td>\n",
       "      <td>5</td>\n",
       "      <td>311</td>\n",
       "      <td>15.2</td>\n",
       "      <td>386.71</td>\n",
       "      <td>17.10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID     crim    zn  indus  chas    nox     rm    age     dis  rad  tax  \\\n",
       "0   3  0.02729   0.0   7.07     0  0.469  7.185   61.1  4.9671    2  242   \n",
       "1   6  0.02985   0.0   2.18     0  0.458  6.430   58.7  6.0622    3  222   \n",
       "2   8  0.14455  12.5   7.87     0  0.524  6.172   96.1  5.9505    5  311   \n",
       "3   9  0.21124  12.5   7.87     0  0.524  5.631  100.0  6.0821    5  311   \n",
       "4  10  0.17004  12.5   7.87     0  0.524  6.004   85.9  6.5921    5  311   \n",
       "\n",
       "   ptratio   black  lstat  \n",
       "0     17.8  392.83   4.03  \n",
       "1     18.7  394.12   5.21  \n",
       "2     15.2  396.90  19.15  \n",
       "3     15.2  386.63  29.93  \n",
       "4     15.2  386.71  17.10  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BostonTrain.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d3c0a49f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 173 entries, 0 to 172\n",
      "Data columns (total 14 columns):\n",
      " #   Column   Non-Null Count  Dtype  \n",
      "---  ------   --------------  -----  \n",
      " 0   ID       173 non-null    int64  \n",
      " 1   crim     173 non-null    float64\n",
      " 2   zn       173 non-null    float64\n",
      " 3   indus    173 non-null    float64\n",
      " 4   chas     173 non-null    int64  \n",
      " 5   nox      173 non-null    float64\n",
      " 6   rm       173 non-null    float64\n",
      " 7   age      173 non-null    float64\n",
      " 8   dis      173 non-null    float64\n",
      " 9   rad      173 non-null    int64  \n",
      " 10  tax      173 non-null    int64  \n",
      " 11  ptratio  173 non-null    float64\n",
      " 12  black    173 non-null    float64\n",
      " 13  lstat    173 non-null    float64\n",
      "dtypes: float64(10), int64(4)\n",
      "memory usage: 19.1 KB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>crim</th>\n",
       "      <th>zn</th>\n",
       "      <th>indus</th>\n",
       "      <th>chas</th>\n",
       "      <th>nox</th>\n",
       "      <th>rm</th>\n",
       "      <th>age</th>\n",
       "      <th>dis</th>\n",
       "      <th>rad</th>\n",
       "      <th>tax</th>\n",
       "      <th>ptratio</th>\n",
       "      <th>black</th>\n",
       "      <th>lstat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>173.000000</td>\n",
       "      <td>173.000000</td>\n",
       "      <td>173.000000</td>\n",
       "      <td>173.000000</td>\n",
       "      <td>173.000000</td>\n",
       "      <td>173.000000</td>\n",
       "      <td>173.000000</td>\n",
       "      <td>173.000000</td>\n",
       "      <td>173.000000</td>\n",
       "      <td>173.000000</td>\n",
       "      <td>173.000000</td>\n",
       "      <td>173.000000</td>\n",
       "      <td>173.000000</td>\n",
       "      <td>173.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>258.404624</td>\n",
       "      <td>4.100862</td>\n",
       "      <td>12.661850</td>\n",
       "      <td>10.835145</td>\n",
       "      <td>0.086705</td>\n",
       "      <td>0.549981</td>\n",
       "      <td>6.321237</td>\n",
       "      <td>69.245665</td>\n",
       "      <td>3.958865</td>\n",
       "      <td>9.387283</td>\n",
       "      <td>406.231214</td>\n",
       "      <td>18.469942</td>\n",
       "      <td>351.299711</td>\n",
       "      <td>12.917977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>143.289788</td>\n",
       "      <td>10.607761</td>\n",
       "      <td>24.536277</td>\n",
       "      <td>6.596488</td>\n",
       "      <td>0.282219</td>\n",
       "      <td>0.117826</td>\n",
       "      <td>0.700621</td>\n",
       "      <td>28.248244</td>\n",
       "      <td>2.324131</td>\n",
       "      <td>8.662621</td>\n",
       "      <td>164.480626</td>\n",
       "      <td>2.196196</td>\n",
       "      <td>99.781464</td>\n",
       "      <td>7.293408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.013810</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.460000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.392000</td>\n",
       "      <td>4.138000</td>\n",
       "      <td>2.900000</td>\n",
       "      <td>1.178100</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>187.000000</td>\n",
       "      <td>12.600000</td>\n",
       "      <td>0.320000</td>\n",
       "      <td>1.920000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>136.000000</td>\n",
       "      <td>0.082210</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.320000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.447000</td>\n",
       "      <td>5.895000</td>\n",
       "      <td>42.800000</td>\n",
       "      <td>2.010700</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>279.000000</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>371.720000</td>\n",
       "      <td>6.870000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>268.000000</td>\n",
       "      <td>0.251990</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.560000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.538000</td>\n",
       "      <td>6.223000</td>\n",
       "      <td>79.200000</td>\n",
       "      <td>3.421100</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>330.000000</td>\n",
       "      <td>19.100000</td>\n",
       "      <td>390.070000</td>\n",
       "      <td>12.120000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>381.000000</td>\n",
       "      <td>3.673670</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>18.100000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.624000</td>\n",
       "      <td>6.674000</td>\n",
       "      <td>94.600000</td>\n",
       "      <td>5.400700</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>666.000000</td>\n",
       "      <td>20.200000</td>\n",
       "      <td>396.060000</td>\n",
       "      <td>17.210000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>505.000000</td>\n",
       "      <td>88.976200</td>\n",
       "      <td>95.000000</td>\n",
       "      <td>27.740000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.871000</td>\n",
       "      <td>8.780000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>12.126500</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>711.000000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>396.900000</td>\n",
       "      <td>34.370000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               ID        crim          zn       indus        chas         nox  \\\n",
       "count  173.000000  173.000000  173.000000  173.000000  173.000000  173.000000   \n",
       "mean   258.404624    4.100862   12.661850   10.835145    0.086705    0.549981   \n",
       "std    143.289788   10.607761   24.536277    6.596488    0.282219    0.117826   \n",
       "min      3.000000    0.013810    0.000000    0.460000    0.000000    0.392000   \n",
       "25%    136.000000    0.082210    0.000000    5.320000    0.000000    0.447000   \n",
       "50%    268.000000    0.251990    0.000000    8.560000    0.000000    0.538000   \n",
       "75%    381.000000    3.673670   20.000000   18.100000    0.000000    0.624000   \n",
       "max    505.000000   88.976200   95.000000   27.740000    1.000000    0.871000   \n",
       "\n",
       "               rm         age         dis         rad         tax     ptratio  \\\n",
       "count  173.000000  173.000000  173.000000  173.000000  173.000000  173.000000   \n",
       "mean     6.321237   69.245665    3.958865    9.387283  406.231214   18.469942   \n",
       "std      0.700621   28.248244    2.324131    8.662621  164.480626    2.196196   \n",
       "min      4.138000    2.900000    1.178100    1.000000  187.000000   12.600000   \n",
       "25%      5.895000   42.800000    2.010700    4.000000  279.000000   17.000000   \n",
       "50%      6.223000   79.200000    3.421100    5.000000  330.000000   19.100000   \n",
       "75%      6.674000   94.600000    5.400700   24.000000  666.000000   20.200000   \n",
       "max      8.780000  100.000000   12.126500   24.000000  711.000000   22.000000   \n",
       "\n",
       "            black       lstat  \n",
       "count  173.000000  173.000000  \n",
       "mean   351.299711   12.917977  \n",
       "std     99.781464    7.293408  \n",
       "min      0.320000    1.920000  \n",
       "25%    371.720000    6.870000  \n",
       "50%    390.070000   12.120000  \n",
       "75%    396.060000   17.210000  \n",
       "max    396.900000   34.370000  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BostonTrain.info()\n",
    "BostonTrain.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1752945d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = BostonTrain.iloc[:,1:-1].values\n",
    "Y = BostonTrain.iloc[:,-1].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a0f33884",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7121414b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(103, 12)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bab2136f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(103,)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d65ab0c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "413c617a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4a2c85ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,664</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │         \u001b[38;5;34m1,664\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_4 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m8,256\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_5 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m65\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">9,985</span> (39.00 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m9,985\u001b[0m (39.00 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">9,985</span> (39.00 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m9,985\u001b[0m (39.00 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(128, activation='relu', input_shape=X_train[0].shape))\n",
    "model.add(Dense(64,activation = 'relu'))\n",
    "model.add(Dense(1,activation = 'linear'))\n",
    "model.compile(optimizer = 'adam', loss = 'mse', metrics = ['mae'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1f3b6ef8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 550.9615 - mae: 18.2372 - val_loss: 49.8473 - val_mae: 5.2450\n",
      "Epoch 2/100\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 98.4209 - mae: 8.3625 - val_loss: 54.6479 - val_mae: 5.4532\n",
      "Epoch 3/100\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 73.7323 - mae: 6.4879 - val_loss: 46.5231 - val_mae: 5.9541\n",
      "Epoch 4/100\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 88.6716 - mae: 7.3959 - val_loss: 81.6962 - val_mae: 6.3184\n",
      "Epoch 5/100\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 85.5629 - mae: 7.8099 - val_loss: 191.8321 - val_mae: 12.5071\n",
      "Epoch 6/100\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 110.6756 - mae: 8.3710 - val_loss: 224.3847 - val_mae: 12.3544\n",
      "Epoch 7/100\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 125.0318 - mae: 7.9747 - val_loss: 72.7678 - val_mae: 6.8858\n",
      "Epoch 8/100\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 69.9944 - mae: 6.8080 - val_loss: 120.0570 - val_mae: 10.1078\n",
      "Epoch 9/100\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 47.5031 - mae: 5.4114 - val_loss: 50.5930 - val_mae: 6.1036\n",
      "Epoch 10/100\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 46.8204 - mae: 5.4627 - val_loss: 36.2284 - val_mae: 5.0384\n",
      "Epoch 11/100\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 78.1474 - mae: 6.6417 - val_loss: 137.7006 - val_mae: 7.1183\n",
      "Epoch 12/100\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 60.8372 - mae: 6.4068 - val_loss: 38.5390 - val_mae: 4.6100\n",
      "Epoch 13/100\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 59.8030 - mae: 6.0951 - val_loss: 84.5722 - val_mae: 7.8818\n",
      "Epoch 14/100\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 84.6502 - mae: 7.5434 - val_loss: 36.5990 - val_mae: 4.6799\n",
      "Epoch 15/100\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 45.5118 - mae: 5.0479 - val_loss: 25.9536 - val_mae: 3.8736\n",
      "Epoch 16/100\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 34.9540 - mae: 4.5017 - val_loss: 91.0724 - val_mae: 7.1604\n",
      "Epoch 17/100\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 95.2547 - mae: 7.8900 - val_loss: 39.0051 - val_mae: 4.3251\n",
      "Epoch 18/100\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 34.4045 - mae: 4.1645 - val_loss: 29.1414 - val_mae: 4.2791\n",
      "Epoch 19/100\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 34.8671 - mae: 4.6078 - val_loss: 30.3257 - val_mae: 4.3865\n",
      "Epoch 20/100\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 64.7056 - mae: 6.2319 - val_loss: 32.0740 - val_mae: 3.6288\n",
      "Epoch 21/100\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 53.1776 - mae: 5.6418 - val_loss: 34.6961 - val_mae: 3.8560\n",
      "Epoch 22/100\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 56.5382 - mae: 5.3207 - val_loss: 38.7689 - val_mae: 4.4263\n",
      "Epoch 23/100\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 26.7931 - mae: 3.6129 - val_loss: 48.0628 - val_mae: 5.4474\n",
      "Epoch 24/100\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 76.4033 - mae: 6.9897 - val_loss: 65.3105 - val_mae: 6.5557\n",
      "Epoch 25/100\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 60.1083 - mae: 6.3806 - val_loss: 40.1569 - val_mae: 5.1806\n",
      "Epoch 26/100\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 35.3513 - mae: 4.6651 - val_loss: 37.7283 - val_mae: 5.1596\n",
      "Epoch 27/100\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 33.9811 - mae: 4.6381 - val_loss: 29.2662 - val_mae: 4.1435\n",
      "Epoch 28/100\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 49.4210 - mae: 5.2297 - val_loss: 40.3334 - val_mae: 5.1439\n",
      "Epoch 29/100\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 41.6311 - mae: 4.9525 - val_loss: 31.0447 - val_mae: 4.3106\n",
      "Epoch 30/100\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 36.2421 - mae: 4.6400 - val_loss: 38.2410 - val_mae: 5.0817\n",
      "Epoch 31/100\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 32.7826 - mae: 4.4457 - val_loss: 27.3243 - val_mae: 3.8886\n",
      "Epoch 32/100\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 33.0171 - mae: 4.4930 - val_loss: 31.8461 - val_mae: 3.9547\n",
      "Epoch 33/100\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 37.6811 - mae: 4.6745 - val_loss: 27.3902 - val_mae: 3.9523\n",
      "Epoch 34/100\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 34.8165 - mae: 4.6651 - val_loss: 77.5345 - val_mae: 7.5002\n",
      "Epoch 35/100\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 36.8918 - mae: 4.6192 - val_loss: 25.4694 - val_mae: 3.7154\n",
      "Epoch 36/100\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 31.8957 - mae: 4.2820 - val_loss: 24.1749 - val_mae: 3.5903\n",
      "Epoch 37/100\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 42.5237 - mae: 5.0007 - val_loss: 30.2357 - val_mae: 4.0154\n",
      "Epoch 38/100\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 42.1701 - mae: 4.6515 - val_loss: 26.9340 - val_mae: 3.8768\n",
      "Epoch 39/100\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 31.1852 - mae: 4.0895 - val_loss: 26.0521 - val_mae: 3.8218\n",
      "Epoch 40/100\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 23.9640 - mae: 3.8912 - val_loss: 127.4720 - val_mae: 9.9987\n",
      "Epoch 41/100\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 59.7481 - mae: 5.8172 - val_loss: 29.5051 - val_mae: 4.0490\n",
      "Epoch 42/100\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 48.3171 - mae: 5.0481 - val_loss: 28.8310 - val_mae: 4.0141\n",
      "Epoch 43/100\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 23.8964 - mae: 3.7414 - val_loss: 52.1273 - val_mae: 6.0849\n",
      "Epoch 44/100\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 27.1873 - mae: 3.9531 - val_loss: 33.0456 - val_mae: 4.6268\n",
      "Epoch 45/100\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 32.3686 - mae: 4.3442 - val_loss: 30.5997 - val_mae: 4.2317\n",
      "Epoch 46/100\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 25.4804 - mae: 3.8678 - val_loss: 28.9947 - val_mae: 4.0364\n",
      "Epoch 47/100\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 29.7064 - mae: 4.3529 - val_loss: 24.0835 - val_mae: 3.5459\n",
      "Epoch 48/100\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 43.1666 - mae: 4.8959 - val_loss: 37.7043 - val_mae: 5.0274\n",
      "Epoch 49/100\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 28.3973 - mae: 3.9694 - val_loss: 25.4513 - val_mae: 3.8186\n",
      "Epoch 50/100\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 20.6411 - mae: 3.3511 - val_loss: 31.9541 - val_mae: 4.3421\n",
      "Epoch 51/100\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 39.4756 - mae: 4.8841 - val_loss: 34.5222 - val_mae: 4.7714\n",
      "Epoch 52/100\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 56.7167 - mae: 6.0125 - val_loss: 27.8201 - val_mae: 3.8400\n",
      "Epoch 53/100\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 35.0050 - mae: 4.3272 - val_loss: 31.5260 - val_mae: 4.3319\n",
      "Epoch 54/100\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 31.9415 - mae: 4.3579 - val_loss: 29.9795 - val_mae: 3.8960\n",
      "Epoch 55/100\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 26.6695 - mae: 3.9028 - val_loss: 32.1586 - val_mae: 4.4686\n",
      "Epoch 56/100\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 38.2825 - mae: 4.5085 - val_loss: 25.2284 - val_mae: 3.6683\n",
      "Epoch 57/100\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 27.3242 - mae: 3.7967 - val_loss: 47.4142 - val_mae: 5.7594\n",
      "Epoch 58/100\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 40.8138 - mae: 4.9867 - val_loss: 28.7274 - val_mae: 3.8932\n",
      "Epoch 59/100\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 25.1510 - mae: 3.8619 - val_loss: 50.6306 - val_mae: 5.9257\n",
      "Epoch 60/100\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 42.4657 - mae: 4.7269 - val_loss: 27.3026 - val_mae: 3.8686\n",
      "Epoch 61/100\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 28.8476 - mae: 4.2107 - val_loss: 25.0875 - val_mae: 3.6358\n",
      "Epoch 62/100\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 29.1385 - mae: 4.2672 - val_loss: 28.3612 - val_mae: 3.9124\n",
      "Epoch 63/100\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 36.8191 - mae: 4.8079 - val_loss: 33.6462 - val_mae: 4.4350\n",
      "Epoch 64/100\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 31.1600 - mae: 4.3045 - val_loss: 27.4267 - val_mae: 3.7887\n",
      "Epoch 65/100\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 33.8581 - mae: 4.3922 - val_loss: 24.1451 - val_mae: 3.4242\n",
      "Epoch 66/100\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 32.0138 - mae: 4.1105 - val_loss: 27.3570 - val_mae: 3.9160\n",
      "Epoch 67/100\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 27.1490 - mae: 3.8742 - val_loss: 26.3063 - val_mae: 3.6448\n",
      "Epoch 68/100\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 30.1883 - mae: 3.8992 - val_loss: 29.6053 - val_mae: 3.9031\n",
      "Epoch 69/100\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 23.0720 - mae: 3.6623 - val_loss: 38.9233 - val_mae: 4.7653\n",
      "Epoch 70/100\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 27.6390 - mae: 3.8522 - val_loss: 40.8282 - val_mae: 5.1671\n",
      "Epoch 71/100\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 28.1081 - mae: 3.9671 - val_loss: 35.3305 - val_mae: 4.7934\n",
      "Epoch 72/100\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 32.0615 - mae: 4.3912 - val_loss: 39.8680 - val_mae: 5.0858\n",
      "Epoch 73/100\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 29.9019 - mae: 4.0353 - val_loss: 25.8950 - val_mae: 3.6201\n",
      "Epoch 74/100\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 29.4245 - mae: 3.8522 - val_loss: 25.6431 - val_mae: 3.6124\n",
      "Epoch 75/100\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 21.5887 - mae: 3.3614 - val_loss: 30.5515 - val_mae: 4.0613\n",
      "Epoch 76/100\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 32.9656 - mae: 4.5017 - val_loss: 28.2664 - val_mae: 4.0435\n",
      "Epoch 77/100\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 27.8143 - mae: 4.0497 - val_loss: 30.5867 - val_mae: 4.0299\n",
      "Epoch 78/100\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 25.7114 - mae: 3.5618 - val_loss: 24.6973 - val_mae: 3.5322\n",
      "Epoch 79/100\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 30.0129 - mae: 3.9458 - val_loss: 40.4105 - val_mae: 5.1078\n",
      "Epoch 80/100\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 22.0176 - mae: 3.5965 - val_loss: 32.9967 - val_mae: 4.1287\n",
      "Epoch 81/100\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 20.3804 - mae: 3.0840 - val_loss: 35.6904 - val_mae: 4.6266\n",
      "Epoch 82/100\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 22.7128 - mae: 3.4236 - val_loss: 29.5613 - val_mae: 3.8952\n",
      "Epoch 83/100\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 29.4282 - mae: 4.2785 - val_loss: 30.2154 - val_mae: 3.9175\n",
      "Epoch 84/100\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 27.6494 - mae: 3.7299 - val_loss: 36.4120 - val_mae: 4.7110\n",
      "Epoch 85/100\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 22.6286 - mae: 3.6965 - val_loss: 27.6117 - val_mae: 3.9073\n",
      "Epoch 86/100\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 22.1770 - mae: 3.2929 - val_loss: 26.6710 - val_mae: 3.7691\n",
      "Epoch 87/100\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 30.0071 - mae: 4.2775 - val_loss: 43.6969 - val_mae: 5.0952\n",
      "Epoch 88/100\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 16.9678 - mae: 2.8969 - val_loss: 32.1452 - val_mae: 4.1432\n",
      "Epoch 89/100\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 27.6231 - mae: 3.9425 - val_loss: 37.6499 - val_mae: 4.4847\n",
      "Epoch 90/100\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 28.0700 - mae: 4.1448 - val_loss: 30.4979 - val_mae: 3.8206\n",
      "Epoch 91/100\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 31.8447 - mae: 4.3105 - val_loss: 36.3850 - val_mae: 4.6315\n",
      "Epoch 92/100\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 25.4689 - mae: 3.5875 - val_loss: 24.5596 - val_mae: 3.4753\n",
      "Epoch 93/100\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 21.8245 - mae: 3.2874 - val_loss: 33.7289 - val_mae: 4.2368\n",
      "Epoch 94/100\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 27.8628 - mae: 3.8546 - val_loss: 31.8943 - val_mae: 4.0844\n",
      "Epoch 95/100\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 27.7458 - mae: 3.8120 - val_loss: 26.3930 - val_mae: 3.5923\n",
      "Epoch 96/100\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 24.5988 - mae: 3.5842 - val_loss: 42.7047 - val_mae: 5.2332\n",
      "Epoch 97/100\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 22.2860 - mae: 3.4461 - val_loss: 26.4813 - val_mae: 3.7719\n",
      "Epoch 98/100\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 24.4421 - mae: 3.6341 - val_loss: 39.2057 - val_mae: 4.4304\n",
      "Epoch 99/100\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 19.0886 - mae: 3.0992 - val_loss: 28.3087 - val_mae: 3.7759\n",
      "Epoch 100/100\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 25.2783 - mae: 3.7025 - val_loss: 30.8377 - val_mae: 3.9878\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x1c4957ca390>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, epochs = 100, batch_size = 1, validation_data = (X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e95c7c16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([9.6040e-02, 4.0000e+01, 6.4100e+00, 0.0000e+00, 4.4700e-01,\n",
       "       6.8540e+00, 4.2800e+01, 4.2673e+00, 4.0000e+00, 2.5400e+02,\n",
       "       1.7600e+01, 3.9690e+02])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test[8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5c9dcf48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actual Value:  2.98\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step\n",
      "Predicted Value:  6.61089\n"
     ]
    }
   ],
   "source": [
    "print(\"Actual Value: \", y_test[8])\n",
    "sample = np.array([X_test[8]])\n",
    "print(\"Predicted Value: \", model.predict(sample)[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f7a0ee34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "Mean Squared Error (MSE): 30.83767284885964\n",
      "Mean Absolute Error (MAE): 3.9877668527875634\n",
      "R² Score: 0.3747534428685457\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "y_true = y_test.values if hasattr(y_test, 'values') else y_test\n",
    "\n",
    "mse = mean_squared_error(y_true, y_pred)\n",
    "mae = mean_absolute_error(y_true, y_pred)\n",
    "r2 = r2_score(y_true, y_pred)\n",
    "\n",
    "print(\"Mean Squared Error (MSE):\", mse)\n",
    "print(\"Mean Absolute Error (MAE):\", mae)\n",
    "print(\"R² Score:\", r2)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (tf_env)",
   "language": "python",
   "name": "tf_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
